{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec413b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis module is responsible for reading outage email files from a folder\\nand using an LLM (like GPT-4) to extract structured information\\nsuch as partner name, outage duration, cause, etc.\\n\\nThe output is returned as a pandas DataFrame that can later be loaded\\ninto DuckDB for analytics and reporting.\\n\\nHigh-level workflow:\\n1. Read all `.txt` email files from a folder.\\n2. For each email, send the text to the LLM.\\n3. Ask the LLM to return JSON data with fixed fields.\\n4. Convert all outputs into a clean DataFrame.\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This module is responsible for reading outage email files from a folder\n",
    "and using an LLM (like GPT-4) to extract structured information\n",
    "such as partner name, outage duration, cause, etc.\n",
    "\n",
    "The output is returned as a pandas DataFrame that can later be loaded\n",
    "into DuckDB for analytics and reporting.\n",
    "\n",
    "High-level workflow:\n",
    "1. Read all `.txt` email files from a folder.\n",
    "2. For each email, send the text to the LLM.\n",
    "3. Ask the LLM to return JSON data with fixed fields.\n",
    "4. Convert all outputs into a clean DataFrame.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a842c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI Utils\\Partner Performance Report\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI  # LangChain's OpenAI chat model interface\n",
    "from dotenv import load_dotenv \n",
    "from pathlib import Path\n",
    "load_dotenv(override=True)  # take environment variables from .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1f9931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global_Hitec_Outage_Emails GLOBAL_HITEC_OUTAGE_JSON\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Read environment variables\n",
    "# -------------------------------\n",
    "HITEC_EMAIL_DIR = os.getenv(\"GLOBAL_HITEC_EMAIL_DIR\")\n",
    "HITEC_EMAIL_JSON = os.getenv(\"GLOBAL_HITEC_EMAIL_JSON\")\n",
    "print(HITEC_EMAIL_DIR, HITEC_EMAIL_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a99603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# STEP 1: Create a helper function to initialize the LLM model\n",
    "# -------------------------------------------------------------------\n",
    "def get_llm(model_name=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    This function initializes the Large Language Model (LLM).\n",
    "    In this case, weâ€™re using the GPT-4 model provided through LangChain.\n",
    "\n",
    "    - model_name: defines which OpenAI model to use.\n",
    "    - temperature: controls randomness (0 = deterministic answers).\n",
    "\n",
    "    Returns:\n",
    "        llm object â†’ can be used to call llm.predict(prompt)\n",
    "    \"\"\"\n",
    "    \n",
    "    return ChatOpenAI(model_name=model_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc016d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# STEP 2: Define the LLM prompt template\n",
    "# -------------------------------------------------------------------\n",
    "PARSER_PROMPT = \"\"\"\n",
    "You are an expert system that parses structured outage summary emails.\n",
    "Your task is to extract outage-related details from the email below.\n",
    "\n",
    "Extract the following fields and return ONLY valid JSON (no explanations):\n",
    "\n",
    "- partner_name\n",
    "- outage_type\n",
    "- issue_details\n",
    "- current_status\n",
    "- business_impact\n",
    "- manual_processing\n",
    "- root_cause_available\n",
    "- outage_start_time (ISO 8601 format)\n",
    "- outage_end_time (ISO 8601 format)\n",
    "- duration_hours (numeric)\n",
    "- resolution_details\n",
    "- email_subject\n",
    "- email_date\n",
    "\n",
    "Input Email:\n",
    "-------------------\n",
    "{email_text}\n",
    "-------------------\n",
    "\n",
    "Rules:\n",
    "- Return only valid JSON.\n",
    "- Convert all dates to ISO 8601 format (e.g., 2025-11-05T07:48:00-08:00).\n",
    "- If data is missing, put null.\n",
    "- If start and end times exist, calculate duration_hours.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e6659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 3: Create a function to parse ONE email using LLM\n",
    "# -------------------------------------------------------------------\n",
    "from urllib import response\n",
    "\n",
    "\n",
    "def parse_outage_email(llm, email_text: str):\n",
    "    \"\"\"\n",
    "    Sends one emailâ€™s text to the LLM and returns a parsed JSON object.\n",
    "\n",
    "    Parameters:\n",
    "        llm        â†’ The initialized LLM model object (from get_llm()).\n",
    "        email_text â†’ The raw text of one outage email.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing all parsed fields + a timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the LLM prompt by inserting the email text into the template\n",
    "    prompt = PARSER_PROMPT.format(email_text=email_text)\n",
    "\n",
    "    try:\n",
    "        # Send the prompt to the LLM and capture its response\n",
    "        response = llm.invoke(prompt)\n",
    "        raw_response = response.content.strip()\n",
    "\n",
    "        # The LLM might include extra text before/after JSON, so extract clean JSON only\n",
    "        start = raw_response.find(\"{\")\n",
    "        end = raw_response.rfind(\"}\")\n",
    "        if start == -1 or end == -1:\n",
    "            raise ValueError(\"No valid JSON object found in LLM response.\")\n",
    "\n",
    "        # Extract JSON substring\n",
    "        json_str = raw_response[start:end+1]\n",
    "\n",
    "        # Convert JSON string into Python dictionary\n",
    "        parsed = json.loads(json_str)\n",
    "\n",
    "    except Exception as e:\n",
    "        # If something goes wrong (bad format, LLM failure, etc.)\n",
    "        # we capture the error but still return a record (so processing continues)\n",
    "        parsed = {\n",
    "            \"error\": str(e),\n",
    "            \"raw_text\": email_text[:2000]  # keep partial text for debugging\n",
    "        }\n",
    "\n",
    "    # Add a timestamp to track when this email was parsed\n",
    "    parsed[\"parsed_at\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "    # Return a Python dictionary of the parsed data\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30df4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 4: Parse ALL emails from a folder\n",
    "# -------------------------------------------------------------------\n",
    "def parse_emails_from_folder(folder_path: str, llm):\n",
    "    \"\"\"\n",
    "    Reads all text (.txt) email files from the given folder,\n",
    "    uses the LLM to parse each one, and returns a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path â†’ path to folder containing email files\n",
    "        llm         â†’ LLM object returned by get_llm()\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame containing one row per email with structured fields\n",
    "    \"\"\"\n",
    "    #Create full directory path\n",
    "    full_folder_path = Path(folder_path)\n",
    "    #print(\"full folder path *********\" + str(full_folder_path))\n",
    "    # Create an empty list to hold results\n",
    "    records = []\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for file in os.listdir(full_folder_path):\n",
    "        # Skip non-text files\n",
    "        if not file.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        # Full file path\n",
    "        full_path = os.path.join(full_folder_path, file)\n",
    "        #print(\"full file path *********\" + str(full_path))\n",
    "\n",
    "        # Read the email content from the file\n",
    "        with open(full_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            email_text = f.read()\n",
    "\n",
    "        #print(f\"ðŸ” Parsing email file: {file} ...\")\n",
    "\n",
    "        # Parse one email using the LLM\n",
    "        parsed = parse_outage_email(llm, email_text)\n",
    "\n",
    "        # Keep track of the original file name for traceability\n",
    "        parsed[\"source_file\"] = file\n",
    "\n",
    "        # Add parsed dictionary to list\n",
    "        records.append(parsed)\n",
    "\n",
    "    # Convert list of dictionaries into a pandas DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    print(f\"âœ… Parsed {len(df)} emails successfully.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4543c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "storage.py\n",
    "-----------\n",
    "This module handles storing the parsed outage email data\n",
    "into a DuckDB database.\n",
    "\n",
    "DuckDB is a lightweight, high-speed, SQL-based analytical database\n",
    "that runs in a single file (like SQLite, but optimized for analytics).\n",
    "\n",
    "The workflow:\n",
    "1. Initialize a DuckDB connection and create a table (if not exists).\n",
    "2. Insert parsed data (from a pandas DataFrame) into that table.\n",
    "\"\"\"\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 1: Define the database schema (table structure)\n",
    "# -------------------------------------------------------------------\n",
    "DB_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS outages (\n",
    "    partner_name VARCHAR,\n",
    "    outage_type VARCHAR,\n",
    "    issue_details VARCHAR,\n",
    "    current_status VARCHAR,\n",
    "    business_impact VARCHAR,\n",
    "    manual_processing VARCHAR,\n",
    "    root_cause_available VARCHAR,\n",
    "    outage_start_time TIMESTAMP,\n",
    "    outage_end_time TIMESTAMP,\n",
    "    duration_hours DOUBLE,\n",
    "    resolution_details VARCHAR,\n",
    "    email_subject VARCHAR,\n",
    "    email_date DATE,\n",
    "    parsed_at TIMESTAMP,\n",
    "    source_file VARCHAR\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 2: Function to initialize DuckDB\n",
    "# -------------------------------------------------------------------\n",
    "def init_db(in_memory=True):\n",
    "    \"\"\"\n",
    "    Initializes the DuckDB database.\n",
    "\n",
    "    Parameters:\n",
    "        in_memory â†’ if True, creates a temporary DB (for testing);\n",
    "                     if False, saves data to a local file \"outages.duckdb\".\n",
    "\n",
    "    Returns:\n",
    "        Connection object â†’ used to run SQL commands.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a connection to the database\n",
    "    if in_memory:\n",
    "        con = duckdb.connect(database=\":memory:\")\n",
    "        print(\"ðŸ§  Using in-memory DuckDB (data will be lost after shutdown).\")\n",
    "    else:\n",
    "        con = duckdb.connect(database=\"outages.duckdb\")\n",
    "        print(\"ðŸ’¾ Using persistent DuckDB file (outages.duckdb).\")\n",
    "\n",
    "    # Create table if it doesnâ€™t exist yet\n",
    "    con.execute(DB_SCHEMA)\n",
    "    return con\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 3: Function to load a DataFrame into DuckDB\n",
    "# -------------------------------------------------------------------\n",
    "def load_dataframe_to_duckdb(con, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Inserts the parsed outage email data (from pandas DataFrame)\n",
    "    into the 'outages' table in DuckDB.\n",
    "\n",
    "    Parameters:\n",
    "        con â†’ active DuckDB connection\n",
    "        df  â†’ pandas DataFrame containing parsed email data\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ No records found â€” nothing to insert.\")\n",
    "        return\n",
    "\n",
    "    # Register the DataFrame as a temporary table in DuckDB\n",
    "    con.register(\"df_temp\", df)\n",
    "\n",
    "    # Insert data into the main outages table using SQL\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO outages\n",
    "        SELECT \n",
    "            partner_name,\n",
    "            outage_type,\n",
    "            issue_details,\n",
    "            current_status,\n",
    "            business_impact,\n",
    "            manual_processing,\n",
    "            root_cause_available,\n",
    "            outage_start_time,\n",
    "            outage_end_time,\n",
    "            duration_hours,\n",
    "            resolution_details,\n",
    "            email_subject,\n",
    "            email_date,\n",
    "            parsed_at,\n",
    "            source_file\n",
    "        FROM df_temp\n",
    "    \"\"\")\n",
    "\n",
    "    # Unregister temporary table\n",
    "    con.unregister(\"df_temp\")\n",
    "\n",
    "    #print(f\"âœ… {len(df)} records loaded into DuckDB successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffaa8b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Initialize the LLM\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mget_llm\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 2: Parse all emails from folder\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m parse_emails_from_folder(HITEC_EMAIL_DIR, llm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_llm' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Initialize the LLM\n",
    "llm = get_llm()\n",
    "\n",
    "# Step 2: Parse all emails from folder\n",
    "df = parse_emails_from_folder(HITEC_EMAIL_DIR, llm)\n",
    "#print(df.head())\n",
    "\n",
    "# Step 3: Initialize database\n",
    "con = init_db(in_memory=False)\n",
    "\n",
    "#Delete existing data in outages table\n",
    "con.execute(\"DELETE FROM outages\")\n",
    "\n",
    "# Step 4: Load parsed data into DuckDB\n",
    "load_dataframe_to_duckdb(con, df)\n",
    "\n",
    "# Step 5: Run a test SQL query\n",
    "print(\"***********Running test query on outages table:******************\")\n",
    "print(\"Total outages:\", con.execute(\"SELECT count(*) FROM outages\").df())\n",
    "#print(con.execute(\"SELECT * FROM outages\").df())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
