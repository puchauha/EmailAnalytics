{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7bdd4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis module is responsible for reading outage email files from a folder\\nand using an LLM (like GPT-4) to extract structured information\\nsuch as partner name, outage duration, cause, etc.\\n\\nThe output is returned as a pandas DataFrame that can later be loaded\\ninto DuckDB for analytics and reporting.\\n\\nHigh-level workflow:\\n1. Read all `.txt` email files from a folder.\\n2. For each email, send the text to the LLM.\\n3. Ask the LLM to return JSON data with fixed fields.\\n4. Convert all outputs into a clean DataFrame.\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This module is responsible for reading outage email files from a folder\n",
    "and using an LLM (like GPT-4) to extract structured information\n",
    "such as partner name, outage duration, cause, etc.\n",
    "\n",
    "The output is returned as a pandas DataFrame that can later be loaded\n",
    "into DuckDB for analytics and reporting.\n",
    "\n",
    "High-level workflow:\n",
    "1. Read all `.txt` email files from a folder.\n",
    "2. For each email, send the text to the LLM.\n",
    "3. Ask the LLM to return JSON data with fixed fields.\n",
    "4. Convert all outputs into a clean DataFrame.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29cd1eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI  # LangChain's OpenAI chat model interface\n",
    "from dotenv import load_dotenv \n",
    "from pathlib import Path\n",
    "load_dotenv(override=True)  # take environment variables from .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66c78c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\AI Utils\\Partner Performance Report\\Global_Hitec_Outage_Emails GLOBAL_HITEC_OUTAGE_JSON\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Read environment variables\n",
    "# -------------------------------\n",
    "HITEC_EMAIL_DIR = os.getenv(\"GLOBAL_HITEC_EMAIL_DIR\")\n",
    "HITEC_EMAIL_JSON = os.getenv(\"GLOBAL_HITEC_EMAIL_JSON\")\n",
    "print(HITEC_EMAIL_DIR, HITEC_EMAIL_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3abdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# STEP 1: Create a helper function to initialize the LLM model\n",
    "# -------------------------------------------------------------------\n",
    "def get_llm(model_name=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    This function initializes the Large Language Model (LLM).\n",
    "    In this case, weâ€™re using the GPT-4 model provided through LangChain.\n",
    "\n",
    "    - model_name: defines which OpenAI model to use.\n",
    "    - temperature: controls randomness (0 = deterministic answers).\n",
    "\n",
    "    Returns:\n",
    "        llm object â†’ can be used to call llm.predict(prompt)\n",
    "    \"\"\"\n",
    "    \n",
    "    return ChatOpenAI(model_name=model_name, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4cd6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# STEP 2: Define the LLM prompt template\n",
    "# -------------------------------------------------------------------\n",
    "PARSER_PROMPT = \"\"\"\n",
    "You are an expert system that parses structured outage summary emails.\n",
    "Your task is to extract outage-related details from the email below.\n",
    "\n",
    "Extract the following fields and return ONLY valid JSON (no explanations):\n",
    "\n",
    "- partner_name\n",
    "- outage_type\n",
    "- issue_details\n",
    "- current_status\n",
    "- business_impact\n",
    "- manual_processing\n",
    "- root_cause_available\n",
    "- outage_start_time (ISO 8601 format)\n",
    "- outage_end_time (ISO 8601 format)\n",
    "- duration_hours (numeric)\n",
    "- resolution_details\n",
    "- email_subject\n",
    "- email_date\n",
    "\n",
    "Input Email:\n",
    "-------------------\n",
    "{email_text}\n",
    "-------------------\n",
    "\n",
    "Rules:\n",
    "- Return only valid JSON.\n",
    "- Convert all dates to ISO 8601 format (e.g., 2025-11-05T07:48:00-08:00).\n",
    "- If data is missing, put null.\n",
    "- If start and end times exist, calculate duration_hours.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be7dcf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 3: Create a function to parse ONE email using LLM\n",
    "# -------------------------------------------------------------------\n",
    "from urllib import response\n",
    "\n",
    "\n",
    "def parse_outage_email(llm, email_text: str):\n",
    "    \"\"\"\n",
    "    Sends one emailâ€™s text to the LLM and returns a parsed JSON object.\n",
    "\n",
    "    Parameters:\n",
    "        llm        â†’ The initialized LLM model object (from get_llm()).\n",
    "        email_text â†’ The raw text of one outage email.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing all parsed fields + a timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the LLM prompt by inserting the email text into the template\n",
    "    prompt = PARSER_PROMPT.format(email_text=email_text)\n",
    "\n",
    "    try:\n",
    "        # Send the prompt to the LLM and capture its response\n",
    "        response = llm.invoke(prompt)\n",
    "        raw_response = response.content.strip()\n",
    "\n",
    "        # The LLM might include extra text before/after JSON, so extract clean JSON only\n",
    "        start = raw_response.find(\"{\")\n",
    "        end = raw_response.rfind(\"}\")\n",
    "        if start == -1 or end == -1:\n",
    "            raise ValueError(\"No valid JSON object found in LLM response.\")\n",
    "\n",
    "        # Extract JSON substring\n",
    "        json_str = raw_response[start:end+1]\n",
    "\n",
    "        # Convert JSON string into Python dictionary\n",
    "        parsed = json.loads(json_str)\n",
    "\n",
    "    except Exception as e:\n",
    "        # If something goes wrong (bad format, LLM failure, etc.)\n",
    "        # we capture the error but still return a record (so processing continues)\n",
    "        parsed = {\n",
    "            \"error\": str(e),\n",
    "            \"raw_text\": email_text[:2000]  # keep partial text for debugging\n",
    "        }\n",
    "\n",
    "    # Add a timestamp to track when this email was parsed\n",
    "    parsed[\"parsed_at\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "    # Return a Python dictionary of the parsed data\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f56f2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 4: Parse ALL emails from a folder\n",
    "# -------------------------------------------------------------------\n",
    "def parse_emails_from_folder(folder_path: str, llm):\n",
    "    \"\"\"\n",
    "    Reads all text (.txt) email files from the given folder,\n",
    "    uses the LLM to parse each one, and returns a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path â†’ path to folder containing email files\n",
    "        llm         â†’ LLM object returned by get_llm()\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame containing one row per email with structured fields\n",
    "    \"\"\"\n",
    "    #Create full directory path\n",
    "    full_folder_path = Path(folder_path)\n",
    "    print(\"full folder path *********\" + str(full_folder_path))\n",
    "    # Create an empty list to hold results\n",
    "    records = []\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for file in os.listdir(full_folder_path):\n",
    "        # Skip non-text files\n",
    "        if not file.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        # Full file path\n",
    "        full_path = os.path.join(full_folder_path, file)\n",
    "        print(\"full file path *********\" + str(full_path))\n",
    "\n",
    "        # Read the email content from the file\n",
    "        with open(full_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            email_text = f.read()\n",
    "\n",
    "        print(f\"ðŸ” Parsing email file: {file} ...\")\n",
    "\n",
    "        # Parse one email using the LLM\n",
    "        parsed = parse_outage_email(llm, email_text)\n",
    "\n",
    "        # Keep track of the original file name for traceability\n",
    "        parsed[\"source_file\"] = file\n",
    "\n",
    "        # Add parsed dictionary to list\n",
    "        records.append(parsed)\n",
    "\n",
    "    # Convert list of dictionaries into a pandas DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    print(f\"âœ… Parsed {len(df)} emails successfully.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fdbeab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "storage.py\n",
    "-----------\n",
    "This module handles storing the parsed outage email data\n",
    "into a DuckDB database.\n",
    "\n",
    "DuckDB is a lightweight, high-speed, SQL-based analytical database\n",
    "that runs in a single file (like SQLite, but optimized for analytics).\n",
    "\n",
    "The workflow:\n",
    "1. Initialize a DuckDB connection and create a table (if not exists).\n",
    "2. Insert parsed data (from a pandas DataFrame) into that table.\n",
    "\"\"\"\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 1: Define the database schema (table structure)\n",
    "# -------------------------------------------------------------------\n",
    "DB_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS outages (\n",
    "    partner_name VARCHAR,\n",
    "    outage_type VARCHAR,\n",
    "    issue_details VARCHAR,\n",
    "    current_status VARCHAR,\n",
    "    business_impact VARCHAR,\n",
    "    manual_processing VARCHAR,\n",
    "    root_cause_available VARCHAR,\n",
    "    outage_start_time TIMESTAMP,\n",
    "    outage_end_time TIMESTAMP,\n",
    "    duration_hours DOUBLE,\n",
    "    resolution_details VARCHAR,\n",
    "    email_subject VARCHAR,\n",
    "    email_date DATE,\n",
    "    parsed_at TIMESTAMP,\n",
    "    source_file VARCHAR\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 2: Function to initialize DuckDB\n",
    "# -------------------------------------------------------------------\n",
    "def init_db(in_memory=True):\n",
    "    \"\"\"\n",
    "    Initializes the DuckDB database.\n",
    "\n",
    "    Parameters:\n",
    "        in_memory â†’ if True, creates a temporary DB (for testing);\n",
    "                     if False, saves data to a local file \"outages.duckdb\".\n",
    "\n",
    "    Returns:\n",
    "        Connection object â†’ used to run SQL commands.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a connection to the database\n",
    "    if in_memory:\n",
    "        con = duckdb.connect(database=\":memory:\")\n",
    "        print(\"ðŸ§  Using in-memory DuckDB (data will be lost after shutdown).\")\n",
    "    else:\n",
    "        con = duckdb.connect(database=\"outages.duckdb\")\n",
    "        print(\"ðŸ’¾ Using persistent DuckDB file (outages.duckdb).\")\n",
    "\n",
    "    # Create table if it doesnâ€™t exist yet\n",
    "    con.execute(DB_SCHEMA)\n",
    "    return con\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# STEP 3: Function to load a DataFrame into DuckDB\n",
    "# -------------------------------------------------------------------\n",
    "def load_dataframe_to_duckdb(con, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Inserts the parsed outage email data (from pandas DataFrame)\n",
    "    into the 'outages' table in DuckDB.\n",
    "\n",
    "    Parameters:\n",
    "        con â†’ active DuckDB connection\n",
    "        df  â†’ pandas DataFrame containing parsed email data\n",
    "    \"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ No records found â€” nothing to insert.\")\n",
    "        return\n",
    "\n",
    "    # Register the DataFrame as a temporary table in DuckDB\n",
    "    con.register(\"df_temp\", df)\n",
    "\n",
    "    # Insert data into the main outages table using SQL\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO outages\n",
    "        SELECT \n",
    "            partner_name,\n",
    "            outage_type,\n",
    "            issue_details,\n",
    "            current_status,\n",
    "            business_impact,\n",
    "            manual_processing,\n",
    "            root_cause_available,\n",
    "            outage_start_time,\n",
    "            outage_end_time,\n",
    "            duration_hours,\n",
    "            resolution_details,\n",
    "            email_subject,\n",
    "            email_date,\n",
    "            parsed_at,\n",
    "            source_file\n",
    "        FROM df_temp\n",
    "    \"\"\")\n",
    "\n",
    "    # Unregister temporary table\n",
    "    con.unregister(\"df_temp\")\n",
    "\n",
    "    print(f\"âœ… {len(df)} records loaded into DuckDB successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ede5793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_tools.py\n",
    "\n",
    "import json\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from email.message import EmailMessage\n",
    "import smtplib\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "def create_llm(model_name=\"gpt-4o-mini\"):\n",
    "    return ChatOpenAI(model_name=model_name, temperature=0)\n",
    "\n",
    "def run_sql_tool_factory(con):\n",
    "    print(\"Creating run_sql tool\")\n",
    "    def run_sql(sql):\n",
    "        print(f\"Executing SQL: {sql}\")\n",
    "        forbidden = [\"INSERT\",\"UPDATE\",\"DELETE\",\"DROP\",\"ALTER\",\"CREATE\",\"--\",\";\"]\n",
    "        if any(k in sql.upper() for k in forbidden):\n",
    "            return json.dumps({\"error\": \"Forbidden SQL command\"})\n",
    "        try:\n",
    "            df = con.execute(sql).df()\n",
    "            # convert datetimes\n",
    "            for c in df.columns:\n",
    "                if \"datetime\" in str(df[c].dtype):\n",
    "                    df[c] = df[c].astype(str)\n",
    "            return df.to_json(orient=\"records\")\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "    return run_sql\n",
    "\n",
    "def create_chart_tool(data_json, chart_type=\"bar\", x=None, y=None):\n",
    "    data = json.loads(data_json)\n",
    "    if not data:\n",
    "        raise ValueError(\"Empty data\")\n",
    "\n",
    "    cols = list(data[0].keys())\n",
    "    x = x or cols[0]\n",
    "    y = y or cols[1]\n",
    "\n",
    "    xs = [str(r[x]) for r in data]\n",
    "    ys = [r[y] for r in data]\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    if chart_type == \"line\":\n",
    "        plt.plot(xs, ys, marker=\"o\")\n",
    "    else:\n",
    "        plt.bar(xs, ys)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    plt.close()\n",
    "\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(buf.read()).decode()\n",
    "\n",
    "def create_ppt_tool_factory(con):\n",
    "    def create_ppt(design_json):\n",
    "        design = json.loads(design_json)\n",
    "        prs = Presentation()\n",
    "\n",
    "        for slide_spec in design.get(\"slides\", []):\n",
    "            layout = prs.slide_layouts[0] if slide_spec[\"type\"] == \"title\" else prs.slide_layouts[1]\n",
    "            slide = prs.slides.add_slide(layout)\n",
    "            slide.shapes.title.text = slide_spec[\"title\"]\n",
    "\n",
    "            if slide_spec[\"type\"] == \"title\":\n",
    "                slide.placeholders[1].text = slide_spec.get(\"subtitle\",\"\")\n",
    "                continue\n",
    "\n",
    "            if slide_spec[\"type\"] == \"table\":\n",
    "                sql = slide_spec[\"sql\"]\n",
    "                table_json = run_sql_tool_factory(con)(sql)\n",
    "                data = json.loads(table_json)\n",
    "\n",
    "                if not data:\n",
    "                    continue\n",
    "\n",
    "                cols = list(data[0].keys())\n",
    "                rows = len(data)\n",
    "\n",
    "                table = slide.shapes.add_table(\n",
    "                    rows+1, len(cols),\n",
    "                    Inches(0.5), Inches(1.5),\n",
    "                    Inches(9), Inches(3)\n",
    "                ).table\n",
    "\n",
    "                for i,c in enumerate(cols):\n",
    "                    table.cell(0,i).text = c\n",
    "\n",
    "                for r in range(rows):\n",
    "                    for c in range(len(cols)):\n",
    "                        table.cell(r+1, c).text = str(data[r][cols[c]])\n",
    "\n",
    "            if slide_spec[\"type\"] == \"chart\":\n",
    "                sql = slide_spec[\"sql\"]\n",
    "                chart_data = run_sql_tool_factory(con)(sql)\n",
    "                chart_uri = create_chart_tool(chart_data, slide_spec[\"chart_type\"])\n",
    "\n",
    "                img_bytes = base64.b64decode(chart_uri.split(\",\")[1])\n",
    "                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\").name\n",
    "                with open(tmp,\"wb\") as f:\n",
    "                    f.write(img_bytes)\n",
    "\n",
    "                slide.shapes.add_picture(tmp, Inches(1), Inches(1.5), width=Inches(8))\n",
    "                os.remove(tmp)\n",
    "\n",
    "        filename = design.get(\"filename\",\"report.pptx\")\n",
    "        prs.save(filename)\n",
    "        return filename\n",
    "\n",
    "    return create_ppt\n",
    "\n",
    "def send_email_tool_factory(smtp_cfg):\n",
    "    def send_email(to_email, subject, body, attachment_path):\n",
    "        msg = EmailMessage()\n",
    "        msg[\"To\"] = to_email\n",
    "        msg[\"From\"] = smtp_cfg[\"user\"]\n",
    "        msg[\"Subject\"] = subject\n",
    "        msg.set_content(body)\n",
    "\n",
    "        with open(attachment_path,\"rb\") as f:\n",
    "            data = f.read()\n",
    "\n",
    "        msg.add_attachment(\n",
    "            data,\n",
    "            maintype=\"application\",\n",
    "            subtype=\"vnd.openxmlformats-officedocument.presentationml.presentation\",\n",
    "            filename=os.path.basename(attachment_path)\n",
    "        )\n",
    "\n",
    "        with smtplib.SMTP(smtp_cfg[\"host\"], smtp_cfg[\"port\"]) as s:\n",
    "            s.starttls()\n",
    "            s.login(smtp_cfg[\"user\"], smtp_cfg[\"password\"])\n",
    "            s.send_message(msg)\n",
    "\n",
    "        return f\"Email sent to {to_email}\"\n",
    "\n",
    "    return send_email\n",
    "\n",
    "def build_tools(con, smtp_cfg):\n",
    "    return [\n",
    "        Tool(name=\"run_sql\", func=run_sql_tool_factory(con), description=\"Run SQL on outages table\"),\n",
    "        Tool(name=\"create_chart\", func=create_chart_tool, description=\"Create chart from data\"),\n",
    "        Tool(name=\"create_ppt\", func=create_ppt_tool_factory(con), description=\"Generate PPT\"),\n",
    "        Tool(name=\"send_email\", func=send_email_tool_factory(smtp_cfg), description=\"Send email with attachment\")\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "# ----------------- STREAMLIT CONFIG ------------------\n",
    "st.set_page_config(page_title=\"Outage Monitoring POC\", layout=\"wide\")\n",
    "st.title(\"ðŸ”Œ Outage Monitoring POC\")\n",
    "\n",
    "# ----------------- INIT DB & LLM ---------------------\n",
    "con = init_db(in_memory=True)\n",
    "llm = create_llm()\n",
    "\n",
    "SMTP_CFG = {\n",
    "    \"host\": \"smtp.gmail.com\",\n",
    "    \"port\": 587,\n",
    "    \"user\": \"your_email@gmail.com\",\n",
    "    \"password\": \"your_app_password\"\n",
    "}\n",
    "\n",
    "tools = build_tools(con, SMTP_CFG)\n",
    "# Create the agent\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "# Create an executor to run it\n",
    "#agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# ----------------- SIDEBAR ---------------------------\n",
    "mode = st.sidebar.radio(\"Mode\", [\"Chat\", \"Report Builder\", \"Admin\"])\n",
    "\n",
    "# ----------------- CHAT MODE -------------------------\n",
    "if mode == \"Chat\":\n",
    "    st.header(\"ðŸ’¬ Chat with Outage Assistant\")\n",
    "\n",
    "    if \"history\" not in st.session_state:\n",
    "        st.session_state.history = []\n",
    "\n",
    "    user_msg = st.chat_input(\"Ask something about outagesâ€¦\")\n",
    "    if user_msg:\n",
    "        st.session_state.history.append((\"user\", user_msg))\n",
    "\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(user_msg)\n",
    "\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            resp = agent.invoke(user_msg)\n",
    "            st.write(resp)\n",
    "            st.session_state.history.append((\"assistant\", resp))\n",
    "\n",
    "    for role, msg in st.session_state.history:\n",
    "        with st.chat_message(role):\n",
    "            st.write(msg)\n",
    "\n",
    "# ----------------- REPORT BUILDER ---------------------\n",
    "elif mode == \"Report Builder\":\n",
    "    st.header(\"ðŸ“Š Report Builder\")\n",
    "\n",
    "    prompt = st.text_area(\"Describe the report to generate\")\n",
    "\n",
    "    if st.button(\"Generate Report\"):\n",
    "        with st.spinner(\"Generating...\"):\n",
    "            resp = agent.invoke(prompt)\n",
    "\n",
    "        st.write(resp)\n",
    "\n",
    "        # Auto-detect PPT generated\n",
    "        ppts = [f for f in os.listdir(\".\") if f.endswith(\".pptx\")]\n",
    "        if ppts:\n",
    "            latest = sorted(ppts)[-1]\n",
    "            with open(latest,\"rb\") as f:\n",
    "                st.download_button(\"â¬‡ Download PPT\", f, file_name=latest)\n",
    "\n",
    "# ----------------- ADMIN MODE ------------------------\n",
    "elif mode == \"Admin\":\n",
    "    st.header(\"ðŸ›  Admin Mode\")\n",
    "\n",
    "    st.subheader(\"1. Load Outage Emails from Local Folder (POC)\")\n",
    "    folder = st.text_input(\"Email folder path\", \"./emails\")\n",
    "\n",
    "    if st.button(\"Parse Emails\"):\n",
    "        df = parse_emails_from_folder(folder, llm)\n",
    "        st.dataframe(df.head())\n",
    "        load_dataframe_to_duckdb(con, df)\n",
    "        st.success(\"Emails parsed and loaded into DuckDB!\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"2. ZIP Upload (coming soon)\")\n",
    "    st.info(\"This feature will be added later.\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"3. IMAP Email Ingestion (coming soon)\")\n",
    "    st.info(\"IMAP integration will be added in a future sprint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5cae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Initialize the LLM\n",
    "llm = get_llm()\n",
    "\n",
    "# Step 2: Parse all emails from folder\n",
    "df = parse_emails_from_folder(HITEC_EMAIL_DIR, llm)\n",
    "print(df.head())\n",
    "\n",
    "# Step 3: Initialize database\n",
    "con = init_db(in_memory=False)\n",
    "\n",
    "# Step 4: Load parsed data into DuckDB\n",
    "load_dataframe_to_duckdb(con, df)\n",
    "\n",
    "# Step 5: Run a test SQL query\n",
    "print(con.execute(\"SELECT * FROM outages\").df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "# --- Init LLM and DB ---\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "con = init_db(in_memory=False)\n",
    "SMTP_CFG = {\n",
    "    \"host\": \"smtp.gmail.com\",\n",
    "    \"port\": 587,\n",
    "    \"user\": \"your_email@gmail.com\",\n",
    "    \"password\": \"your_app_password\"\n",
    "}\n",
    "tools = build_tools(con, SMTP_CFG)\n",
    "\n",
    "# --- âœ… Bind tools to LLM so it can call them ---\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm_with_tools,\n",
    "    tools=tools,\n",
    "    system_prompt=(\n",
    "        \"You are OutageAnalysisAgent â€” an expert in analyzing IT outage data stored in DuckDB.\\n\"\n",
    "        \"You have these tools:\\n\"\n",
    "        \"  - run_sql(sql): runs a SQL query and returns JSON records.\\n\"\n",
    "        \"  - create_chart(data_json, chart_type, x, y): plots data.\\n\"\n",
    "        \"  - create_ppt(design_json): creates presentation slides.\\n\\n\"\n",
    "        \"The outages table has these columns:\\n\"\n",
    "        \"  partner_name, outage_type, issue_details, current_status, business_impact,\\n\"\n",
    "        \"  manual_processing, root_cause_available, outage_start_time, outage_end_time,\\n\"\n",
    "        \"  duration_hours, resolution_details, email_subject, email_date, parsed_at, source_file.\\n\\n\"\n",
    "        \"Follow this process:\\n\"\n",
    "        \"1ï¸âƒ£ When asked to show, count, or compare outage data â€” call `run_sql()` with an explicit SQL query.\\n\"\n",
    "        \"2ï¸âƒ£ Example: to get outages per partner in last month:\\n\"\n",
    "        \"   run_sql('SELECT partner_name, COUNT(*) AS total_outages FROM outages WHERE email_date >= CURRENT_DATE - INTERVAL 30 DAY GROUP BY partner_name')\\n\"\n",
    "        \"3ï¸âƒ£ Then summarize the results in plain English.\\n\"\n",
    "        \"Do not ask clarifying questions; just use the tools and return the answer.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# --- Run test query ---\n",
    "response = agent.invoke({\"input\": \"Show total outages per partner for the last six month.\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f46a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# --- Helper functions -------------------------------------------------------\n",
    "\n",
    "def _try_run_limit0(con, sql):\n",
    "    \"\"\"Try running SQL with LIMIT 0 to check if it's valid in DuckDB.\"\"\"\n",
    "    if not sql.strip():\n",
    "        return False, \"Empty SQL\"\n",
    "    try:\n",
    "        test_sql = sql if re.search(r\"\\bLIMIT\\b\", sql, flags=re.IGNORECASE) else f\"{sql.rstrip(';')} LIMIT 0\"\n",
    "        con.execute(test_sql)\n",
    "        return True, None\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "\n",
    "def normalize_sql_to_duckdb(raw_sql: str, con, max_retries: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Uses the LLM to automatically translate arbitrary SQL into DuckDB-compatible SQL.\n",
    "    Falls back to safe regex replacements if validation fails.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    raw_sql = (raw_sql or \"\").strip()\n",
    "    if not raw_sql:\n",
    "        raise ValueError(\"Empty SQL provided to normalize_sql_to_duckdb\")\n",
    "\n",
    "    base_prompt = f\"\"\"\n",
    "    You are a SQL dialect translator. Convert this SQL into valid DuckDB SQL.\n",
    "    Return **only** the corrected SQL (no markdown, no code fences, no commentary).\n",
    "\n",
    "    If the SQL uses non-DuckDB syntax like DATEADD(), CONVERT(), or INTERVAL -6 MONTH,\n",
    "    rewrite it into DuckDB-compatible form (e.g., CURRENT_DATE - INTERVAL '6' MONTH).\n",
    "\n",
    "    SQL to fix:\n",
    "    {raw_sql}\n",
    "    \"\"\"\n",
    "\n",
    "    candidate_sql = raw_sql\n",
    "    for attempt in range(max_retries):\n",
    "        resp = llm.invoke(base_prompt).content.strip()\n",
    "        resp = re.sub(r\"```(?:sql)?\", \"\", resp, flags=re.IGNORECASE)\n",
    "        resp = resp.replace(\"```\", \"\").strip().rstrip(\";\")\n",
    "\n",
    "        ok, err = _try_run_limit0(con, resp)\n",
    "        if ok:\n",
    "            print(\"âœ… LLM produced valid DuckDB SQL.\")\n",
    "            return resp\n",
    "\n",
    "        # Retry: give the LLM the actual error\n",
    "        print(f\"âš ï¸ Attempt {attempt+1} failed: {err}\")\n",
    "        base_prompt = f\"\"\"\n",
    "        The following SQL failed in DuckDB with error:\n",
    "        {err}\n",
    "\n",
    "        Please fix the SQL so it works in DuckDB.\n",
    "        Return only the corrected SQL text (no markdown, no explanations).\n",
    "\n",
    "        Previous SQL:\n",
    "        {resp}\n",
    "        \"\"\"\n",
    "        candidate_sql = resp\n",
    "\n",
    "    # Final fallback â€” regex-based sanitizer\n",
    "    print(\"âš™ï¸ Falling back to conservative regex fix...\")\n",
    "    fallback = re.sub(r\"```(?:sql)?\", \"\", raw_sql, flags=re.IGNORECASE)\n",
    "    fallback = re.sub(r\"```\", \"\", fallback).strip().rstrip(\";\")\n",
    "    fallback = re.sub(\n",
    "        r\"DATEADD\\s*\\(\\s*month\\s*,\\s*-(\\d+)\\s*,\\s*CURRENT_DATE\\s*\\)\",\n",
    "        r\"CURRENT_DATE - INTERVAL '\\1' MONTH\",\n",
    "        fallback,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    fallback = re.sub(r\"\\bDATEADD\\s*\\(\", \"DATE_ADD(\", fallback, flags=re.IGNORECASE)\n",
    "    fallback = re.sub(r\"INTERVAL\\s*-\\s*(\\d+)\\s*MONTH\", r\"INTERVAL '\\1' MONTH\", fallback, flags=re.IGNORECASE)\n",
    "    ok, err = _try_run_limit0(con, fallback)\n",
    "    if ok:\n",
    "        print(\"âœ… Fallback regex produced valid SQL.\")\n",
    "        return fallback\n",
    "\n",
    "    raise RuntimeError(f\"âŒ Could not fix SQL for DuckDB. Last error: {err}\\nCandidate: {candidate_sql}\")\n",
    "\n",
    "\n",
    "# --- Main LangGraph node: generate_sql() -----------------------------------\n",
    "\n",
    "def generate_sql(state: dict):\n",
    "    \"\"\"\n",
    "    Step 2 in the LangGraph workflow:\n",
    "    Takes a natural-language user query â†’ asks LLM to generate initial SQL â†’ validates/fixes for DuckDB.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "\n",
    "    user_query = state.get(\"user_query\")\n",
    "    con = state.get(\"db_con\")\n",
    "\n",
    "    if not user_query:\n",
    "        raise KeyError(\"Missing 'user_query' in state\")\n",
    "    if not con:\n",
    "        raise KeyError(\"Missing 'db_con' in state\")\n",
    "\n",
    "    print(f\"ðŸ§  Generating SQL for user query: {user_query}\")\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    prompt = f\"\"\"\n",
    "    Generate a DuckDB-compatible SQL SELECT query that answers this question:\n",
    "    {user_query}\n",
    "\n",
    "    Table: outages\n",
    "    Columns: partner_name, outage_type, issue_details, duration_hours, email_date, outage_start_time, outage_end_time\n",
    "\n",
    "    Rules:\n",
    "    - Output only SQL (no markdown or explanation)\n",
    "    - Ensure syntax works in DuckDB\n",
    "    - Use CURRENT_DATE - INTERVAL 'x' MONTH for date filters\n",
    "    \"\"\"\n",
    "    raw_sql = llm.invoke(prompt).content.strip()\n",
    "    print(f\"ðŸ§® Raw SQL (before normalization):\\n{raw_sql}\")\n",
    "\n",
    "    clean_sql = normalize_sql_to_duckdb(raw_sql, con)\n",
    "    print(f\"ðŸ§© Final Clean SQL:\\n{clean_sql}\")\n",
    "\n",
    "    return {\"sql_query\": clean_sql, \"generated_at\": datetime.utcnow().isoformat()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402997e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Outage Analytics Agent using LangGraph\n",
    "--------------------------------------\n",
    "\n",
    "âœ… Parses user queries (like \"show average outage duration per partner for last 6 months\")\n",
    "âœ… Generates SQL dynamically using LLM\n",
    "âœ… Runs SQL against DuckDB\n",
    "âœ… Creates charts + PPTs\n",
    "âœ… Provides natural summaries\n",
    "âœ… Auto-retries with relaxed SQL if query returns empty (self-healing)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import io\n",
    "import base64\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional, Dict, Any\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1ï¸âƒ£ Helper Functions\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def init_db(in_memory=False):\n",
    "    \"\"\"Initialize DuckDB database.\"\"\"\n",
    "    db_file = \":memory:\" if in_memory else \"outages.duckdb\"\n",
    "    con = duckdb.connect(database=db_file)\n",
    "    print(f\"ðŸ’¾ Connected to {db_file}\")\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS outages (\n",
    "            partner_name VARCHAR,\n",
    "            outage_type VARCHAR,\n",
    "            issue_details VARCHAR,\n",
    "            current_status VARCHAR,\n",
    "            business_impact VARCHAR,\n",
    "            manual_processing VARCHAR,\n",
    "            root_cause_available VARCHAR,\n",
    "            outage_start_time TIMESTAMP,\n",
    "            outage_end_time TIMESTAMP,\n",
    "            duration_hours DOUBLE,\n",
    "            resolution_details VARCHAR,\n",
    "            email_subject VARCHAR,\n",
    "            email_date DATE,\n",
    "            parsed_at TIMESTAMP,\n",
    "            source_file VARCHAR\n",
    "        );\n",
    "    \"\"\")\n",
    "    return con\n",
    "\n",
    "\n",
    "def run_sql(con, sql: str):\n",
    "    \"\"\"Run SQL safely on DuckDB.\"\"\"\n",
    "    print(f\"Executing SQL: {sql}\")\n",
    "    try:\n",
    "        df = con.execute(sql).df()\n",
    "        print(f\"âœ… SQL returned {len(df)} rows\")\n",
    "        return df.to_json(orient=\"records\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ SQL Error: {e}\")\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "\n",
    "def create_chart(data_json, chart_type=\"bar\", x=None, y=None):\n",
    "    \"\"\"Generate chart as base64 image.\"\"\"\n",
    "    data = json.loads(data_json)\n",
    "    if not data:\n",
    "        raise ValueError(\"Empty data for chart generation.\")\n",
    "\n",
    "    cols = list(data[0].keys())\n",
    "    x = x or cols[0]\n",
    "    y = y or cols[1]\n",
    "    xs = [str(r[x]) for r in data]\n",
    "    ys = [r[y] for r in data]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    if chart_type == \"line\":\n",
    "        plt.plot(xs, ys, marker=\"o\")\n",
    "    else:\n",
    "        plt.bar(xs, ys)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    plt.close()\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(buf.read()).decode()\n",
    "\n",
    "\n",
    "def create_ppt(data_json, filename=\"outage_summary.pptx\"):\n",
    "    \"\"\"Generate a simple PPT with table data.\"\"\"\n",
    "    data = json.loads(data_json)\n",
    "    prs = Presentation()\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "    slide.shapes.title.text = \"Outage Summary\"\n",
    "\n",
    "    if not data:\n",
    "        slide.placeholders[0].text = \"No outage data found.\"\n",
    "    else:\n",
    "        cols = list(data[0].keys())\n",
    "        rows = len(data)\n",
    "        table = slide.shapes.add_table(\n",
    "            rows+1, len(cols), Inches(0.5), Inches(1.5), Inches(9), Inches(3)\n",
    "        ).table\n",
    "        for i, c in enumerate(cols):\n",
    "            table.cell(0, i).text = c\n",
    "        for r in range(rows):\n",
    "            for c in range(len(cols)):\n",
    "                table.cell(r+1, c).text = str(data[r][cols[c]])\n",
    "\n",
    "    prs.save(filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2ï¸âƒ£ Universal Unwrapping + Helpers\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def unwrap_state(state):\n",
    "    \"\"\"Universal fix â€” unpacks LangGraphâ€™s nested state safely.\"\"\"\n",
    "    if isinstance(state, dict) and \"input\" in state and isinstance(state[\"input\"], dict):\n",
    "        print(\"ðŸª„ Auto-unwrapped LangGraph state.\")\n",
    "        merged = {**state, **state[\"input\"]}\n",
    "        merged.pop(\"input\", None)\n",
    "        return merged\n",
    "    return state\n",
    "\n",
    "\n",
    "def get_db_con(state):\n",
    "    \"\"\"Retrieve DB connection from state.\"\"\"\n",
    "    con = state.get(\"db_con\")\n",
    "    if not con:\n",
    "        raise ValueError(\"Missing database connection in state.\")\n",
    "    return con\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3ï¸âƒ£ Agent State Definition\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    user_query: str\n",
    "    sql_query: Optional[str]\n",
    "    data_json: Optional[str]\n",
    "    chart_uri: Optional[str]\n",
    "    ppt_path: Optional[str]\n",
    "    final_answer: Optional[str]\n",
    "    intent: Optional[Dict[str, Any]]\n",
    "    db_con: Any\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4ï¸âƒ£ Core Nodes\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def interpret_query(state: AgentState):\n",
    "    state = unwrap_state(state)\n",
    "    user_query = state.get(\"user_query\")\n",
    "    if not user_query:\n",
    "        raise KeyError(\"Missing 'user_query' in state input\")\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "    prompt = f\"\"\"\n",
    "    Determine the intent type for this user request and whether a chart or PPT is requested.\n",
    "    Return a JSON object exactly, e.g. {{ \"intent\": \"sql_query\", \"needs_chart\": true, \"notes\": \"...\" }}\n",
    "    Possible intents: sql_query, summary, report\n",
    "    User query: {user_query}\n",
    "    \"\"\"\n",
    "    resp = llm.invoke(prompt).content.strip()\n",
    "    try:\n",
    "        intent = json.loads(resp)\n",
    "    except Exception:\n",
    "        intent = {\"intent\": \"sql_query\", \"needs_chart\": (\"chart\" in user_query.lower()), \"notes\": \"\"}\n",
    "    print(f\"ðŸ§­ Intent: {intent}\")\n",
    "    return {\"intent\": intent, \"user_query\": user_query}\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql(state: AgentState):\n",
    "    state = unwrap_state(state)\n",
    "    sql_query = state.get(\"sql_query\")\n",
    "    con = get_db_con(state)\n",
    "\n",
    "    data_json = run_sql(con, sql_query)\n",
    "    return {\"data_json\": data_json}\n",
    "\n",
    "\n",
    "def retry_if_empty(state: AgentState):\n",
    "    state = unwrap_state(state)\n",
    "    data_json = state.get(\"data_json\")\n",
    "    sql_query = state.get(\"sql_query\")\n",
    "    con = get_db_con(state)\n",
    "\n",
    "    if not data_json or data_json.strip() in [\"\", \"[]\", \"null\", \"None\"]:\n",
    "        print(\"âš ï¸ No data returned, retrying with relaxed SQL...\")\n",
    "    else:\n",
    "        try:\n",
    "            data = json.loads(data_json)\n",
    "            if data and len(data) > 0:\n",
    "                print(\"âœ… Data present â€” skipping retry.\")\n",
    "                return {\"data_json\": data_json, \"sql_query\": sql_query}\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    relaxed_sql = re.sub(\n",
    "        r\"WHERE\\s+email_date\\s*>=\\s*CURRENT_DATE\\s*-\\s*INTERVAL\\s+\\d+\\s+DAY\",\n",
    "        \"\",\n",
    "        sql_query,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    relaxed_sql = re.sub(r\"WHERE\\s*(AND|OR)?\\s*$\", \"\", relaxed_sql, flags=re.IGNORECASE).strip()\n",
    "    print(f\"ðŸ” Retrying with relaxed SQL:\\n{relaxed_sql}\")\n",
    "\n",
    "    data_json_retry = run_sql(con, relaxed_sql)\n",
    "    return {\"data_json\": data_json_retry, \"sql_query\": relaxed_sql}\n",
    "\n",
    "\n",
    "def maybe_chart_and_ppt(state: AgentState):\n",
    "    state = unwrap_state(state)\n",
    "    data_json = state.get(\"data_json\")\n",
    "    intent = state.get(\"intent\", {})\n",
    "    needs_chart = intent.get(\"needs_chart\", True)\n",
    "\n",
    "    chart_uri = ppt_path = None\n",
    "    if data_json and data_json.strip() not in [\"[]\", \"null\", \"None\"]:\n",
    "        if needs_chart:\n",
    "            chart_uri = create_chart(data_json)\n",
    "            print(\"ðŸ“ˆ Chart generated.\")\n",
    "        ppt_path = create_ppt(data_json)\n",
    "        print(f\"ðŸ’¾ PPT created: {ppt_path}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No data available for chart or PPT.\")\n",
    "\n",
    "    return {\"chart_uri\": chart_uri, \"ppt_path\": ppt_path}\n",
    "\n",
    "\n",
    "def summarize_results(state: AgentState):\n",
    "    state = unwrap_state(state)\n",
    "    data_json = state.get(\"data_json\")\n",
    "    user_query = state.get(\"user_query\")\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following outage analytics result for this query:\n",
    "    {user_query}\n",
    "    Data: {data_json[:2000]}\n",
    "    Return a concise business-friendly summary.\n",
    "    \"\"\"\n",
    "    summary = llm.invoke(prompt).content.strip()\n",
    "    print(f\"ðŸ“ Summary: {summary}\")\n",
    "    return {\"final_answer\": summary}\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5ï¸âƒ£ Graph Definition\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def build_outage_agent_graph():\n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    graph.add_node(\"interpret\", interpret_query)\n",
    "    graph.add_node(\"generate_sql\", generate_sql)\n",
    "    graph.add_node(\"execute_sql\", execute_sql)\n",
    "    graph.add_node(\"retry_if_empty\", retry_if_empty)\n",
    "    graph.add_node(\"maybe_chart_and_ppt\", maybe_chart_and_ppt)\n",
    "    graph.add_node(\"summarize\", summarize_results)\n",
    "\n",
    "    graph.add_edge(\"interpret\", \"generate_sql\")\n",
    "    graph.add_edge(\"generate_sql\", \"execute_sql\")\n",
    "    graph.add_edge(\"execute_sql\", \"retry_if_empty\")\n",
    "    graph.add_edge(\"retry_if_empty\", \"maybe_chart_and_ppt\")\n",
    "    graph.add_edge(\"maybe_chart_and_ppt\", \"summarize\")\n",
    "\n",
    "    graph.set_entry_point(\"interpret\")\n",
    "    graph.set_finish_point(\"summarize\")\n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21875da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Connected to outages.duckdb\n",
      "\n",
      "ðŸš€ Running outage analytics agent...\n",
      "\n",
      "ðŸ§­ Intent: {'intent': 'report', 'needs_chart': True, 'notes': 'The user is requesting a report on average outage duration, which typically involves data visualization.'}\n",
      "ðŸ§® Generated Clean SQL:\n",
      "SELECT partner_name, AVG(duration_hours) AS average_outage_duration\n",
      "FROM outages\n",
      "WHERE email_date >= DATE_ADD(CURRENT_DATE, INTERVAL -6 MONTH)\n",
      "GROUP BY partner_name\n",
      "Executing SQL: SELECT partner_name, AVG(duration_hours) AS average_outage_duration\n",
      "FROM outages\n",
      "WHERE email_date >= DATE_ADD(CURRENT_DATE, INTERVAL -6 MONTH)\n",
      "GROUP BY partner_name\n",
      "âŒ SQL Error: Parser Error: syntax error at or near \"MONTH\"\n",
      "\n",
      "LINE 3: WHERE email_date >= DATE_ADD(CURRENT_DATE, INTERVAL -6 MONTH)\n",
      "                                                               ^\n",
      "âœ… Data present â€” skipping retry.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShow average outage duration per partner for the last 6 months\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸš€ Running outage analytics agent...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_query\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdb_con\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== FINAL RESPONSE ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo final answer generated.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\AI Utils\\Partner Performance Report\\.venv\\lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3091\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3092\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3094\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3095\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3096\u001b[0m     config,\n\u001b[0;32m   3097\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3098\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3101\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3102\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3103\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3104\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3105\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3106\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3107\u001b[0m ):\n\u001b[0;32m   3108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3109\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32me:\\AI Utils\\Partner Performance Report\\.venv\\lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2678\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2679\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2680\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2681\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2682\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2683\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2684\u001b[0m ):\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2687\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2688\u001b[0m     )\n\u001b[0;32m   2689\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32me:\\AI Utils\\Partner Performance Report\\.venv\\lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32me:\\AI Utils\\Partner Performance Report\\.venv\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32me:\\AI Utils\\Partner Performance Report\\.venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 656\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32me:\\AI Utils\\Partner Performance Report\\.venv\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[74], line 271\u001b[0m, in \u001b[0;36mmaybe_chart_and_ppt\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_json \u001b[38;5;129;01mand\u001b[39;00m data_json\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_chart:\n\u001b[1;32m--> 271\u001b[0m         chart_uri \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“ˆ Chart generated.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m     ppt_path \u001b[38;5;241m=\u001b[39m create_ppt(data_json)\n",
      "Cell \u001b[1;32mIn[74], line 78\u001b[0m, in \u001b[0;36mcreate_chart\u001b[1;34m(data_json, chart_type, x, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty data for chart generation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;129;01mor\u001b[39;00m cols[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     80\u001b[0m y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;129;01mor\u001b[39;00m cols[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 6ï¸âƒ£ Run Example\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    con = init_db(in_memory=False)\n",
    "    app = build_outage_agent_graph()\n",
    "\n",
    "    user_query = \"Show average outage duration per partner for the last 6 months\"\n",
    "\n",
    "    print(\"\\nðŸš€ Running outage analytics agent...\\n\")\n",
    "    response = app.invoke({\"user_query\": user_query, \"db_con\": con})\n",
    "\n",
    "    print(\"\\n=== FINAL RESPONSE ===\")\n",
    "    print(response.get(\"final_answer\") or \"No final answer generated.\")\n",
    "    if response.get(\"chart_uri\"):\n",
    "        print(\"Chart URI (truncated):\", response[\"chart_uri\"][:200])\n",
    "    if response.get(\"ppt_path\"):\n",
    "        print(\"PPT saved at:\", response[\"ppt_path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
