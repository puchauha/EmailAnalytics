{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9117512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Imports\n",
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2e1314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, TypedDict\n",
    "import base64\n",
    "import io\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "import streamlit as st\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e897ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Environment + LLM + Data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0,api_key=st.secrets[\"OPENAI_API_KEY\"])\n",
    "\n",
    "OUTAGES_EXCEL = \"outages.xlsx\"\n",
    "# Global DataFrame used by the agent\n",
    "df_outages = pd.read_excel(OUTAGES_EXCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ddf661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Prompt definition\n",
    "# ------------------------------------------------------------\n",
    "prompt_summary = \"\"\"\n",
    "You are an expert Python data analyst.\n",
    "\n",
    "You write Pandas code to work with a DataFrame named `df` having these columns:\n",
    "- partner_name (str)\n",
    "- outage_type (str)\n",
    "- issue_details (str)\n",
    "- current_status (str)\n",
    "- business_impact (str)\n",
    "- manual_processing (str/bool)\n",
    "- outage_start_time (datetime/str)\n",
    "- outage_end_time (datetime/str)\n",
    "- duration_hours (float)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32955d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Prompt definition\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "execution_rules = \"\"\"\n",
    "\n",
    "IMPORTANT EXECUTION RULES:\n",
    "- Code MUST be plain Python (NO markdown, NO comments).\n",
    "- Do NOT import pandas or create new DataFrames ‚Äî `df` is already provided.\n",
    "- Convert all datetime fields using:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce').dt.tz_localize(None)\n",
    "- BEFORE any filtering by dates or plotting.\n",
    "- ALWAYS define a final variable named `result`. This is what will be returned.\n",
    "- DO NOT add source file and parsed date details\n",
    "\n",
    "DO NOT write import statements ‚Äî they will cause execution failure.\n",
    "You must only use the following already-available objects:\n",
    "- df  : Pandas DataFrame loaded with outage data\n",
    "- pd  : pandas module\n",
    "- plt : matplotlib.pyplot\n",
    "- io  : io module for BytesIO\n",
    "- base64 : for encoding charts\n",
    "- np  : numpy module\n",
    "\n",
    "If you need a chart:\n",
    "- Use `plt.figure()` before plotting\n",
    "- Save using:\n",
    "    buf = io.BytesIO()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    img_str = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "    result = {\"type\": \"chart\", \"image_base64\": img_str}\n",
    "- NEVER call plt.show()\n",
    "\n",
    "CHART STYLE RULES:\n",
    "- Chart size must be professional and compact:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "- Avoid full-screen or oversized charts.\n",
    "- Use clean white background (default).\n",
    "- Titles should be concise and readable.\n",
    "- Avoid legends if labels are already visible (e.g. pie slices or x-axis labels).\n",
    "- Rotate x-axis labels only if overlapping: plt.xticks(rotation=45)\n",
    "- No alpha transparency effects or neon colors.\n",
    "- Prefer:\n",
    "    - Bar chart ‚Üí plt.bar()\n",
    "    - Line chart ‚Üí plt.plot()\n",
    "    - Pie chart ‚Üí plt.pie() only if < 8 slices\n",
    "- Apply padding for neat layout:\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "If you produce a single number or string, return:\n",
    "    result = {\"type\": \"text_value\", \"value\": <python_value>}\n",
    "\n",
    "\n",
    "AGGREGATION RULES FOR PARTNER-LEVEL OUTPUT:\n",
    "- If the user asks for partner-level outage summaries:\n",
    "    - Ensure exactly one row per partner.\n",
    "    - Include only fields that can be aggregated per partner.\n",
    "    - Aggregate numeric columns like:\n",
    "        - outage_count ‚Üí count()\n",
    "        - total_downtime_hours ‚Üí sum(duration_hours)\n",
    "        - avg_duration_hours ‚Üí mean(duration_hours)\n",
    "    - For business_impact & issue_details:\n",
    "        - Create separate lists using .unique().tolist()\n",
    "        - Name them: unique_business_impacts, unique_issues\n",
    "        \n",
    "    - Do not include raw text columns that cannot be aggregated (like issue_details as a long string)\n",
    "\n",
    "    SCALAR RESULT RULE:\n",
    "    - If the user requests a single answer such as:\n",
    "        - highest / lowest / maximum / minimum outages or downtime\n",
    "        - \"Which partner has the most outages?\"\n",
    "        - \"Show the average downtime overall\"\n",
    "        - \"How many unique partners had outages?\"\n",
    "    - DO NOT create a DataFrame or table.\n",
    "    - Instead compute the metric and return a dict:\n",
    "\n",
    "    result = {\n",
    "        \"type\": \"text_value\",\n",
    "        \"text\": \"MegaTrans Global has the maximum outages (14).\"\n",
    "    }\n",
    "\n",
    "    - Only use DataFrames if user requests multiple rows of results.\n",
    "\n",
    "\n",
    "\n",
    "    OUTPUT RULES:\n",
    "    If user asks for counts, unique values, lists ‚Üí assign to `result` (list/dict/DataFrame).\n",
    "    If user asks a chart:\n",
    "    - Import: import matplotlib.pyplot as plt, import io, import base64, import numpy as np\n",
    "    - Create figure: plt.figure(figsize=(10,6))\n",
    "    - Save chart as base64:\n",
    "        buf = io.BytesIO()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        img_str = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "        result = {\"type\": \"chart\", \"image_base64\": img_str}\n",
    "    - Do NOT use plt.show()\n",
    "\n",
    "    DECISION LOGIC (VERY IMPORTANT):\n",
    "    - If the user asks for a CHART,TRENDS, BAR, PIE, PARETO,Image ‚Üí return type: \"chart\"\n",
    "    - If the user asks for a TABLE ‚Üí return type: \"table\"\n",
    "    - If the request is about BUSINESS IMPACT/TRENDS/AGGREGATE INSIGHTS ‚Üí return type: \"executive_summary\"\n",
    "    - If unclear ‚Üí favor \"table\"\n",
    "\n",
    "    Never let Streamlit decide presentation ‚Äî YOU decide based on query.\n",
    "\n",
    "\n",
    "\n",
    "    If grouping by partner or issue:\n",
    "        - Use .groupby([...], dropna=True)\n",
    "\n",
    "    For renaming:\n",
    "        - DataFrame.rename(columns={{...}}) ‚Äî OK\n",
    "        - NEVER call Series.rename(columns=...)\n",
    "\n",
    "   EXECUTIVE SUMMARY MODE (only if user *explicitly* requests it):\n",
    "- Activated only if user mentions one of:\n",
    "  [\"executive summary\", \"leadership summary\", \"summary for leadership\", \"summary report\"]\n",
    "- Produce both:\n",
    "   * summary_text (3‚Äì4 business insights in English)\n",
    "   * summary_table (per-partner KPI breakdown)\n",
    "- Avoid including non-numeric fields in aggregated tables\n",
    "- Include system chart JSON only if user explicitly mentions chart\n",
    "\n",
    "\n",
    "    FINAL REQUIREMENT:\n",
    "    - Your FINAL LINE must be the assignment: result = ...\n",
    "    - NEVER print or display charts in code.\n",
    "    - Return ONLY the code. No markdown. No explanation.\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a21475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Helper imports for execute_pandas_code\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "import traceback\n",
    "\n",
    "\n",
    "def execute_pandas_code(df: pd.DataFrame, code: str):\n",
    "    \"\"\"\n",
    "    Executes LLM-generated Pandas code safely and returns a structured result.\n",
    "\n",
    "    The LLM is expected to use a DataFrame named `df`.\n",
    "\n",
    "    Possible returned structures:\n",
    "      - {\"type\": \"table\", \"rows\": [...], \"columns\": [...]}\n",
    "      - {\"type\": \"chart\", \"image_base64\": \"...\"}\n",
    "      - {\"type\": \"text\", \"value\": \"...\"}\n",
    "      - {\"type\": \"executive_summary\", \"summary_text\": str, \"rows\": [...], \"columns\": [...]}\n",
    "      - {\"type\": \"error\", \"error_message\": str, \"trace\": str, \"failed_code\": str}\n",
    "      - {\"type\": \"unknown\", \"message\": str}\n",
    "\n",
    "    Notes:\n",
    "      - Strips any `import ...` lines the LLM might generate.\n",
    "      - Normalizes all date/time columns to tz-naive datetimes.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- 1. Local sandbox environment ----------\n",
    "    local_env = {\n",
    "        \"df\": df.copy(),      # work on a copy so original df_outages is safe\n",
    "        \"pd\": pd,\n",
    "        \"plt\": plt,\n",
    "        \"np\": np,\n",
    "        \"io\": io,\n",
    "        \"base64\": base64,\n",
    "    }\n",
    "\n",
    "    # Very restricted builtins to avoid dangerous operations\n",
    "    exec_globals = {\n",
    "        \"__builtins__\": {\n",
    "            \"len\": len,\n",
    "            \"range\": range,\n",
    "            \"min\": min,\n",
    "            \"max\": max,\n",
    "            \"sum\": sum,\n",
    "            \"abs\": abs,\n",
    "            \"round\": round,\n",
    "            \"float\": float,  # <-- Added support for float()\n",
    "            \"int\": int,      # <-- Optional but recommended\n",
    "            \"str\": str,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # ---------- 2. Auto datetime + timezone normalization ----------\n",
    "    for col in df.columns:\n",
    "        lower = col.lower()\n",
    "        if \"date\" in lower or \"time\" in lower:\n",
    "            try:\n",
    "                # Convert to datetime where possible\n",
    "                local_env[\"df\"][col] = pd.to_datetime(\n",
    "                    local_env[\"df\"][col], errors=\"coerce\"\n",
    "                )\n",
    "                # Drop timezone info if present (tz-aware vs tz-naive issues)\n",
    "                if hasattr(local_env[\"df\"][col].dt, \"tz_localize\"):\n",
    "                    try:\n",
    "                        local_env[\"df\"][col] = local_env[\"df\"][col].dt.tz_localize(None)\n",
    "                    except TypeError:\n",
    "                        # In some cases tz_convert is needed first\n",
    "                        try:\n",
    "                            local_env[\"df\"][col] = (\n",
    "                                local_env[\"df\"][col].dt.tz_convert(None)\n",
    "                            )\n",
    "                        except Exception:\n",
    "                            pass\n",
    "            except Exception:\n",
    "                # If conversion fails, just leave the column as is\n",
    "                pass\n",
    "\n",
    "    # ---------- 3. Strip any leading import lines from LLM code ----------\n",
    "    cleaned_lines = []\n",
    "    for line in code.splitlines():\n",
    "        stripped = line.strip()\n",
    "        if stripped.startswith(\"import \") or stripped.startswith(\"from \"):\n",
    "            # Skip imports (we already provided pd, plt, io, base64, np)\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    cleaned_code = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "    print(\"\\nüìå Running Pandas code:\\n\", cleaned_code)\n",
    "\n",
    "    # ---------- 4. Execute the LLM-generated code ----------\n",
    "    try:\n",
    "        exec(cleaned_code, exec_globals, local_env)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Pandas execution error:\", e)\n",
    "        print(traceback.format_exc())\n",
    "        return {\n",
    "            \"type\": \"error\",\n",
    "            \"error_message\": str(e),\n",
    "            \"trace\": traceback.format_exc(),\n",
    "            \"failed_code\": cleaned_code,\n",
    "        }\n",
    "\n",
    "    # ---------- 5. Inspect outputs in priority order ----------\n",
    "\n",
    "    # 5.1 If LLM explicitly set a dict `result` with \"type\", trust it\n",
    "    result = local_env.get(\"result\")\n",
    "    if isinstance(result, dict) and \"type\" in result:\n",
    "        # For table-like dicts the LLM might have used keys like 'data'\n",
    "        # We normalize to rows/columns if it's a DataFrame inside\n",
    "        if isinstance(result.get(\"data\"), pd.DataFrame):\n",
    "            df_res = result[\"data\"]\n",
    "            return {\n",
    "                \"type\": result.get(\"type\", \"table\"),\n",
    "                \"rows\": df_res.to_dict(orient=\"records\"),\n",
    "                \"columns\": list(df_res.columns),\n",
    "            }\n",
    "        return result\n",
    "\n",
    "    # 5.2 Executive summary via summary_text + summary_table\n",
    "    if \"summary_text\" in local_env and \"summary_table\" in local_env:\n",
    "        summary_table = local_env[\"summary_table\"]\n",
    "        if isinstance(summary_table, pd.DataFrame):\n",
    "            return {\n",
    "                \"type\": \"executive_summary\",\n",
    "                \"summary_text\": str(local_env[\"summary_text\"]),\n",
    "                \"rows\": summary_table.to_dict(orient=\"records\"),\n",
    "                \"columns\": list(summary_table.columns),\n",
    "            }\n",
    "\n",
    "    # 5.3 Chart from matplotlib (if any figure was created)\n",
    "    figs = list(map(plt.figure, plt.get_fignums()))\n",
    "    if figs:\n",
    "        buf = io.BytesIO()\n",
    "        # Use the last created figure\n",
    "        figs[-1].savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "        buf.seek(0)\n",
    "        img_str = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "        plt.close(\"all\")\n",
    "        return {\"type\": \"chart\", \"image_base64\": img_str}\n",
    "\n",
    "    # 5.4 DataFrame returned as result\n",
    "    if isinstance(result, pd.DataFrame):\n",
    "        return {\n",
    "            \"type\": \"table\",\n",
    "            \"rows\": result.to_dict(orient=\"records\"),\n",
    "            \"columns\": list(result.columns),\n",
    "        }\n",
    "\n",
    "    # 5.5 List / Series / ndarray ‚Üí represent as a 1-column table\n",
    "    if isinstance(result, (list, np.ndarray, pd.Series)):\n",
    "        df_res = pd.DataFrame({\"value\": list(result)})\n",
    "        return {\n",
    "            \"type\": \"table\",\n",
    "            \"rows\": df_res.to_dict(orient=\"records\"),\n",
    "            \"columns\": [\"value\"],\n",
    "        }\n",
    "\n",
    "    # 5.6 Scalar (int/float/str/bool) ‚Üí text\n",
    "    if isinstance(result, (int, float, str, bool)):\n",
    "        return {\"type\": \"text\", \"value\": str(result)}\n",
    "\n",
    "    # 5.7 If LLM modified df in-place and didn't set result\n",
    "    if \"df\" in local_env and isinstance(local_env[\"df\"], pd.DataFrame):\n",
    "        df_mod = local_env[\"df\"]\n",
    "        return {\n",
    "            \"type\": \"table\",\n",
    "            \"rows\": df_mod.to_dict(orient=\"records\"),\n",
    "            \"columns\": list(df_mod.columns),\n",
    "        }\n",
    "\n",
    "    # 5.8 Fallback: nothing recognizable\n",
    "    return {\n",
    "        \"type\": \"unknown\",\n",
    "        \"message\": \"Code executed but produced no recognized output (no result, chart, or DataFrame).\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8c3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# LangGraph State definition\n",
    "# ------------------------------------------------------------\n",
    "class AgentState(TypedDict, total=False):\n",
    "    user_query: str\n",
    "    pandas_code: str\n",
    "    result: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b35939f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Node: Generate Pandas code from user query\n",
    "# ------------------------------------------------------------\n",
    "def generate_pandas_code(state: AgentState) -> dict:\n",
    "    \"\"\"Node 1: LLM generates Pandas code from the user's query.\"\"\"\n",
    "    user_query = state.get(\"user_query\") or state.get(\"__input__\", {}).get(\"user_query\")\n",
    "    if not user_query:\n",
    "        raise KeyError(\"Missing 'user_query' in state\")\n",
    "\n",
    "    prompt = prompt_summary +  \" User request : \" +user_query + execution_rules \n",
    "    \n",
    "\n",
    "    code = llm.invoke(prompt).content.strip()\n",
    "    return {\"pandas_code\": code}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a156c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Node: Wrap execute_pandas_code for LangGraph\n",
    "# ------------------------------------------------------------\n",
    "def execute_pandas_node(state: AgentState) -> dict:\n",
    "    \"\"\"Node 2: takes the generated code and runs it against df_outages.\"\"\"\n",
    "    code = state.get(\"pandas_code\", \"\")\n",
    "    if not code:\n",
    "        return {\n",
    "            \"result\": {\n",
    "                \"type\": \"error\",\n",
    "                \"error_message\": \"No pandas_code found in state.\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    result = execute_pandas_code(df_outages, code)\n",
    "    return {\"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9776dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_executive_summary(state: AgentState):\n",
    "    result = state.get(\"result\")\n",
    "    user_query = state.get(\"user_query\")\n",
    "    \n",
    "    if not result or (\n",
    "        result.get(\"type\") not in [\"table\", \"chart\", \"text_value\"]\n",
    "    ):\n",
    "        return {\"summary\": None}\n",
    "\n",
    "    # If chart already exists, include caption + insights only\n",
    "    if result.get(\"type\") == \"chart\":\n",
    "        summary_text = result.get(\"summary_text\", \"Chart generated for key outage insights.\")\n",
    "        return {\n",
    "            \"summary\": summary_text,\n",
    "            \"chart_uri\": result.get(\"image_base64\")\n",
    "        }\n",
    "\n",
    "    # Standard summary logic follows...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59677d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Build LangGraph agent #####&&&\n",
    "# ------------------------------------------------------------\n",
    "def build_outage_agent_graph():\n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    graph.add_node(\"generate_pandas_code\", generate_pandas_code)\n",
    "    graph.add_node(\"execute_pandas\", execute_pandas_node)\n",
    "    graph.add_node(\"generate_executive_summary\", generate_executive_summary)\n",
    "\n",
    "    graph.set_entry_point(\"generate_pandas_code\")\n",
    "    graph.add_edge(\"generate_pandas_code\", \"execute_pandas\")\n",
    "    graph.add_edge(\"execute_pandas\", \"generate_executive_summary\")\n",
    "    graph.add_edge(\"generate_executive_summary\", END)\n",
    "\n",
    "    return graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb170f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "st.set_page_config(page_title=\"üìä Outage Analytics Assistant\", layout=\"wide\")\n",
    "st.title(\"üìä Outage Analytics Assistant\")\n",
    "\n",
    "@st.cache_data\n",
    "def load_df():\n",
    "    return pd.read_excel(\"outages.xlsx\")\n",
    "\n",
    "df_outages = load_df()\n",
    "agent = build_outage_agent_graph()\n",
    "\n",
    "st.sidebar.write(f\"Dataset rows: {len(df_outages)}\")\n",
    "\n",
    "query = st.chat_input(\"Ask a question about outages‚Ä¶\")\n",
    "\n",
    "if \"history\" not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "\n",
    "# Render existing history\n",
    "for role, content in st.session_state.history:\n",
    "    with st.chat_message(role):\n",
    "        if isinstance(content, dict):\n",
    "            if content.get(\"type\") == \"chart\":\n",
    "                st.image(base64.b64decode(content[\"image_base64\"]))\n",
    "\n",
    "            elif content.get(\"type\") == \"table\":\n",
    "                st.dataframe(content[\"rows\"], use_container_width=True)\n",
    "\n",
    "            elif content.get(\"type\") in [\"text\", \"text_value\"]:\n",
    "                st.write(content.get(\"text\") or content.get(\"value\"))\n",
    "\n",
    "            elif content.get(\"type\") == \"executive_summary\":\n",
    "                st.subheader(\"üìå Executive Summary\")\n",
    "                st.write(content[\"summary_text\"])\n",
    "                if \"rows\" in content:\n",
    "                    st.dataframe(content[\"rows\"], use_container_width=True)\n",
    "                if \"image_base64\" in content:\n",
    "                    st.image(base64.b64decode(content[\"image_base64\"]))\n",
    "\n",
    "        else:\n",
    "            st.write(content)\n",
    "\n",
    "if query:\n",
    "    # Show user query bubble\n",
    "    st.session_state.history.append((\"user\", query))\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(query)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Processing‚Ä¶\"):\n",
    "            out = agent.invoke({\"user_query\": query})\n",
    "            result = out.get(\"result\")\n",
    "\n",
    "        # Normalize and display instantly\n",
    "        clean_result = result if isinstance(result, dict) else {\n",
    "            \"type\": \"text\",\n",
    "            \"value\": str(result)\n",
    "        }\n",
    "\n",
    "        # Append cleaned result to chat history\n",
    "        st.session_state.history.append((\"assistant\", clean_result))\n",
    "\n",
    "        # Render output now\n",
    "        if clean_result[\"type\"] == \"table\":\n",
    "            st.dataframe(clean_result[\"rows\"], use_container_width=True)\n",
    "\n",
    "        elif clean_result[\"type\"] == \"chart\":\n",
    "            st.image(base64.b64decode(clean_result[\"image_base64\"]), caption=\"Generated Chart\")\n",
    "\n",
    "        elif clean_result[\"type\"] in [\"text\", \"text_value\"]:\n",
    "            st.write(clean_result.get(\"text\") or clean_result.get(\"value\"))\n",
    "\n",
    "        elif clean_result[\"type\"] == \"executive_summary\":\n",
    "            st.subheader(\"üìå Executive Summary\")\n",
    "            st.write(clean_result[\"summary_text\"])\n",
    "            if \"rows\" in clean_result:\n",
    "                st.dataframe(clean_result[\"rows\"], use_container_width=True)\n",
    "            if \"image_base64\" in clean_result:\n",
    "                st.image(base64.b64decode(clean_result[\"image_base64\"]), caption=\"Summary Chart\")\n",
    "\n",
    "        else:\n",
    "            st.write(\"‚ÑπÔ∏è No usable output returned.\")\n",
    "            st.json(clean_result)\n",
    "\n",
    "    # No rerun needed ‚Äî UI already refreshed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
